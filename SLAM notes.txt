between occludin and occluded, there is an area we cant see, which to be explore, there is a space the robot might go to expand the map 
- sudden big difference in distance (from origin) between occluding and occluded edge
- occluded hidden by occluding
- occluding more important occluded, robot finds it first, can search occluded then 
- occluding edge can be the reference point to move straight to the gap 
- assumption: with direction change, the occluding/occluded edges may change as well
- gap = space to explore = can be used for navigation 
- difference of gap tracking to obstacle detection(avoidance): (different navigation strategies)
  - gap tracking provides direction to go 
  - obstacle avoidance no direction to go 
  - autonomous movement, explore path on its own  
  
 - significant of occlusion to intelligent robot navigation
  - occluding mimic human behaviour go finding path to go 
  - obstacle avoidance = reactive model (less thinking), change direction (react) when approach obstacle 
  - occluding higher chance in reaching the end of corridor

Gap tracking algo
- robot pose (x,y,pose)
- how laser work (from left to right fan shape, 0.5 angle dff per beam)
- then, in one laser bean if 2 edges are detected, the one nearer to the robot is occluding, futher one is occluded

global view = combination of local views

slam = simultaneous localization and mapping
- does not concern with navigation strategy, only concerns how map can be build and grow while robot move
- how robot moves, slam does not care

update global view with every local view after each movement = slam 

slam desperately need coordinate

updating need reference frame

every local view has coordinate

local view #0 = global view #0 

laser = rangefinder = more like sonar (weakness: cant detect glass wall, cant detect thin poles)
vision is different, no range (but stereo camera can but stereo still can detect glass wall, need to make assumption)
Answer: add another camera to form stereo image to improve rovio to do SLAM, to get distance based input to compute cartesian coordinate to do mapping


2 methods of SLAM
State of the art method: 
- after each movement, reverse the movement then add the new coordination at the original global view (#0)
- transition first then rotation (when reversing)
- because when move, always turn then move 
- everytime when want to update global view, reverse all the steps until global view #0, then add points there.
- since, many steps to return, drifting accumulated, use mathematics formula to solve

dr zati method:
- only return to previous global view #(n-1)
- register some surfaces as landmarks, add new surfaces based on their related landmarks


drifting prevention
every movement have to move to a point that can be mapped to the refer frame

drifting
1. environment: friction,windy (drone)
2. circuit faulty: motor issues (calibration), power inbalance (wire transfer power differently, short circuited)
